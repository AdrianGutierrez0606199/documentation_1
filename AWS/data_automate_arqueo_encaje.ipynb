{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa3e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Office365-REST-Python-Client\n",
      "  Downloading Office365_REST_Python_Client-2.4.0-py3-none-any.whl (820 kB)\n",
      "     |████████████████████████████████| 820 kB 24.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Office365-REST-Python-Client) (2.26.0)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Office365-REST-Python-Client) (2021.1)\n",
      "Collecting msal\n",
      "  Downloading msal-1.21.0-py2.py3-none-any.whl (89 kB)\n",
      "     |████████████████████████████████| 89 kB 11.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: cryptography<41,>=0.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from msal->Office365-REST-Python-Client) (3.4.4)\n",
      "Collecting PyJWT[crypto]<3,>=1.0.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->Office365-REST-Python-Client) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->Office365-REST-Python-Client) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->Office365-REST-Python-Client) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->Office365-REST-Python-Client) (3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cryptography<41,>=0.6->msal->Office365-REST-Python-Client) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi>=1.12->cryptography<41,>=0.6->msal->Office365-REST-Python-Client) (2.20)\n",
      "Installing collected packages: PyJWT, msal, Office365-REST-Python-Client\n",
      "Successfully installed Office365-REST-Python-Client-2.4.0 PyJWT-2.4.0 msal-1.21.0\n",
      "Collecting office365\n",
      "  Downloading office365-0.3.15-py3-none-any.whl (32 kB)\n",
      "Collecting pymiscutils\n",
      "  Downloading pymiscutils-0.3.14-py3-none-any.whl (14 kB)\n",
      "Collecting maybe-else\n",
      "  Downloading maybe_else-0.2.1-py3-none-any.whl (5.5 kB)\n",
      "Collecting pysubtypes\n",
      "  Downloading pysubtypes-0.3.18-py3-none-any.whl (31 kB)\n",
      "Collecting pyiotools\n",
      "  Downloading pyiotools-0.3.18-py3-none-any.whl (47 kB)\n",
      "     |████████████████████████████████| 47 kB 823 kB/s             \n",
      "\u001b[?25hCollecting pathmagic\n",
      "  Downloading pathmagic-0.3.14-py3-none-any.whl (21 kB)\n",
      "Collecting O365\n",
      "  Downloading O365-2.0.26-py3-none-any.whl (163 kB)\n",
      "     |████████████████████████████████| 163 kB 56.7 MB/s            \n",
      "\u001b[?25hCollecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.13.1-py3-none-any.whl (377 kB)\n",
      "     |████████████████████████████████| 377 kB 73.2 MB/s            \n",
      "\u001b[?25hCollecting azure-core<2.0.0,>=1.23.1\n",
      "  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\n",
      "     |████████████████████████████████| 178 kB 76.1 MB/s            \n",
      "\u001b[?25hCollecting msrest>=0.6.21\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     |████████████████████████████████| 85 kB 1.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from azure-storage-blob->office365) (3.4.4)\n",
      "Collecting requests-oauthlib>=1.2.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting tzlocal>=4.0\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from O365->office365) (2.8.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from O365->office365) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2018.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from O365->office365) (2021.1)\n",
      "Collecting stringcase>=1.2.0\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from O365->office365) (2.26.0)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 30.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathmagic->office365) (1.1.5)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "     |████████████████████████████████| 388 kB 72.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     |████████████████████████████████| 232 kB 74.4 MB/s            \n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: Send2Trash in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathmagic->office365) (1.8.0)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: appdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathmagic->office365) (1.4.4)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathmagic->office365) (0.3.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathmagic->office365) (8.4.0)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.18.4-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "     |████████████████████████████████| 125 kB 73.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyiotools->office365) (0.4.3)\n",
      "Collecting readchar\n",
      "  Downloading readchar-4.0.3-py3-none-any.whl (8.4 kB)\n",
      "Collecting APScheduler\n",
      "  Downloading APScheduler-3.10.1-py3-none-any.whl (59 kB)\n",
      "     |████████████████████████████████| 59 kB 9.7 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: PyQt5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyiotools->office365) (5.12.3)\n",
      "Collecting infi.systray\n",
      "  Downloading infi.systray-0.1.12-py3-none-any.whl (9.2 kB)\n",
      "Collecting cursor\n",
      "  Downloading cursor-1.3.5.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typepy\n",
      "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymiscutils->office365) (1.19.5)\n",
      "Collecting gender-guesser\n",
      "  Downloading gender_guesser-0.4.0-py2.py3-none-any.whl (379 kB)\n",
      "     |████████████████████████████████| 379 kB 61.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyinstrument in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymiscutils->office365) (3.4.2)\n",
      "Collecting msoffcrypto-tool\n",
      "  Downloading msoffcrypto_tool-5.0.0-py3-none-any.whl (33 kB)\n",
      "Collecting html-text\n",
      "  Downloading html_text-0.5.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pysubtypes->office365) (1.26.8)\n",
      "Collecting parsedatetime\n",
      "  Downloading parsedatetime-2.6-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 1.8 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pysubtypes->office365) (2020.11.13)\n",
      "Collecting clipboard\n",
      "  Downloading clipboard-0.0.4.tar.gz (1.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting prettierfier\n",
      "  Downloading prettierfier-1.0.3-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pysubtypes->office365) (0.8.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aenum\n",
      "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
      "     |████████████████████████████████| 131 kB 77.6 MB/s            \n",
      "\u001b[?25hCollecting inflect\n",
      "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n",
      "Collecting case-conversion\n",
      "  Downloading case_conversion-2.1.0.tar.gz (4.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: xlsxwriter in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pysubtypes->office365) (1.3.7)\n",
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob->office365) (4.0.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob->office365) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4>=4.0.0->O365->office365) (2.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cryptography>=2.1.4->azure-storage-blob->office365) (1.14.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from msrest>=0.6.21->azure-storage-blob->office365) (2021.5.30)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     |████████████████████████████████| 41 kB 127 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.0->O365->office365) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.0->O365->office365) (3.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 76.6 MB/s            \n",
      "\u001b[?25hCollecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp36-cp36m-manylinux1_x86_64.whl (70 kB)\n",
      "     |████████████████████████████████| 70 kB 2.1 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from APScheduler->pyiotools->office365) (49.6.0.post20210108)\n",
      "Collecting pyperclip>=1.3\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from html-text->pysubtypes->office365) (4.6.4)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from moviepy->pathmagic->office365) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from moviepy->pathmagic->office365) (4.62.3)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from moviepy->pathmagic->office365) (2.9.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "     |████████████████████████████████| 26.9 MB 41.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: olefile>=0.45 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from msoffcrypto-tool->pysubtypes->office365) (0.46)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyinstrument->pymiscutils->office365) (0.2.4)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyPDF2->pathmagic->office365) (0.8)\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Downloading mbstrdecoder-1.1.1-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->office365) (2.20)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mbstrdecoder<2,>=1.0.0->typepy->pyiotools->office365) (3.0.4)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.7-py2.py3-none-any.whl (340 kB)\n",
      "     |████████████████████████████████| 340 kB 72.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-resources->backports.zoneinfo->tzlocal>=4.0->O365->office365) (3.4.0)\n",
      "Building wheels for collected packages: stringcase, bs4, case-conversion, clipboard, cursor, moviepy, python-docx, pyperclip\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3576 sha256=fc9393893b7e99cc52962a66abe7fe1b3e030be1f8c5858f6131ebe8c80cb058\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/39/ed/1a/d1fbf258dd3b80cf68bdcc602c60f46039c4aacd9ae672b827\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=c8e419deaa6eca97f8080ac013ad3146fa4be4da38b22fe7f29b88f65ca6f6a2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/19/f5/6d/a97dd4f22376d4472d5f4c76c7646876052ff3166b3cf71050\n",
      "  Building wheel for case-conversion (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for case-conversion: filename=case_conversion-2.1.0-py3-none-any.whl size=5360 sha256=fd30233a52db6d070a128c4ddc3c96a3a0e892a1cae38ae4352717985aea2866\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/61/a0/b8/1d6d7fa76f8e720339934ee8998ae1aa67a9442aaac535a614\n",
      "  Building wheel for clipboard (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clipboard: filename=clipboard-0.0.4-py3-none-any.whl size=1848 sha256=3855bd7291545189055d0b1b0371749148e04900ccfaf3bed7db7d9081679d09\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1e/86/2a/3612bf2a0fd7c563462ad5c3403683b55b68a8c36e47bc2648\n",
      "  Building wheel for cursor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cursor: filename=cursor-1.3.5-py3-none-any.whl size=15827 sha256=4532360cd54018b9cd5fe740d9966276832ae1c6fee4764e7b9796f4eb227434\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c2/1c/d6/c85f3edb14b8ed722989929ce5fc08e81f261378d5dc1fc6b6\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110726 sha256=f34452e84dc1b63519e8754bdaaa52a5a0a1c1551709b499d88bcc8dbb084a80\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/be/dc/17/8b4d5a63bcd05dc44db7da57e193372ccd333617293f9deebe\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184600 sha256=452043aca396304f2c377a83d301c45ee201c2a69906d2b4fff9c87f231d7131\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/0a/90/11/0e008b1a5033461d10dff5bf12922d984c59a8f14707c4e7fb\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=14320f7faec5f063b98eb24a2d1588073b11bd49ef4821e8706ce6ff2e3043d0\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/95/38/95/e30a7f0b44cb90642de3469f211a3218f93f871789b4f4b46c\n",
      "Successfully built stringcase bs4 case-conversion clipboard cursor moviepy python-docx pyperclip\n",
      "Installing collected packages: pyperclip, importlib-resources, tzdata, simplejson, proglog, prettierfier, parsedatetime, msoffcrypto-tool, maybe-else, inflect, imageio-ffmpeg, html-text, fuzzywuzzy, colour, clipboard, case-conversion, bs4, backports.zoneinfo, aenum, pytz-deprecation-shim, python-docx, pysubtypes, PyPDF2, pydub, oauthlib, moviepy, tzlocal, requests-oauthlib, readchar, pathmagic, mbstrdecoder, isodate, gender-guesser, cursor, azure-core, typepy, stringcase, pymiscutils, msrest, infi.systray, APScheduler, pyiotools, O365, azure-storage-blob, office365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed APScheduler-3.10.1 O365-2.0.26 PyPDF2-3.0.1 aenum-3.1.11 azure-core-1.24.2 azure-storage-blob-12.13.1 backports.zoneinfo-0.2.1 bs4-0.0.1 case-conversion-2.1.0 clipboard-0.0.4 colour-0.1.5 cursor-1.3.5 fuzzywuzzy-0.18.0 gender-guesser-0.4.0 html-text-0.5.2 imageio-ffmpeg-0.4.8 importlib-resources-5.4.0 infi.systray-0.1.12 inflect-5.3.0 isodate-0.6.1 maybe-else-0.2.1 mbstrdecoder-1.1.1 moviepy-1.0.3 msoffcrypto-tool-5.0.0 msrest-0.7.1 oauthlib-3.2.2 office365-0.3.15 parsedatetime-2.6 pathmagic-0.3.14 prettierfier-1.0.3 proglog-0.1.10 pydub-0.25.1 pyiotools-0.3.18 pymiscutils-0.3.14 pyperclip-1.8.2 pysubtypes-0.3.18 python-docx-0.8.11 pytz-deprecation-shim-0.1.0.post0 readchar-4.0.3 requests-oauthlib-1.3.1 simplejson-3.18.4 stringcase-1.2.0 typepy-1.3.0 tzdata-2022.7 tzlocal-4.2\n",
      "Collecting awswrangler\n",
      "  Downloading awswrangler-2.14.0-py3-none-any.whl (226 kB)\n",
      "     |████████████████████████████████| 226 kB 24.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyarrow<6.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (6.0.1)\n",
      "Collecting numpy<1.19.0,>=1.18.0\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "     |████████████████████████████████| 20.1 MB 57.0 MB/s            \n",
      "\u001b[?25hCollecting requests-aws4auth<2.0.0,>=1.1.1\n",
      "  Downloading requests_aws4auth-1.2.2-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pymysql<1.1.0,>=0.9.0\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "     |████████████████████████████████| 43 kB 1.0 MB/s             \n",
      "\u001b[?25hCollecting redshift-connector<2.1.0,>=2.0.889\n",
      "  Downloading redshift_connector-2.0.910-py3-none-any.whl (112 kB)\n",
      "     |████████████████████████████████| 112 kB 74.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: botocore<2.0.0,>=1.23.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.26.10)\n",
      "Collecting pg8000<1.23.0,>=1.16.0\n",
      "  Downloading pg8000-1.22.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: xlrd<3.0.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (2.0.1)\n",
      "Requirement already satisfied: pandas<1.2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.1.5)\n",
      "Collecting opensearch-py<2.0.0,>=1.0.0\n",
      "  Downloading opensearch_py-1.1.0-py2.py3-none-any.whl (207 kB)\n",
      "     |████████████████████████████████| 207 kB 76.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: openpyxl<3.1.0,>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (3.0.6)\n",
      "Collecting progressbar2<4.0.0,>=3.53.3\n",
      "  Downloading progressbar2-3.55.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.5.3\n",
      "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: xlwt<2.0.0,>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.3.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.23.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (1.26.8)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.15.0)\n",
      "Requirement already satisfied: ply in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (3.11)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (4.4.2)\n",
      "Requirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.2.0,>=1.1.0->awswrangler) (2021.1)\n",
      "Collecting scramp>=1.4.1\n",
      "  Downloading scramp-1.4.1-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-utils>=2.3.0\n",
      "  Downloading python_utils-3.5.2-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.9.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (49.6.0.post20210108)\n",
      "Collecting lxml>=4.6.5\n",
      "  Downloading lxml-4.9.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 70.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.26.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (21.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-utils>=2.3.0->progressbar2<4.0.0,>=3.53.3->awswrangler) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.1)\n",
      "Requirement already satisfied: asn1crypto>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scramp>=1.4.1->pg8000<1.23.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.4.7)\n",
      "Installing collected packages: scramp, python-utils, numpy, lxml, requests-aws4auth, redshift-connector, pymysql, progressbar2, pg8000, opensearch-py, jsonpath-ng, awswrangler\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.6.4\n",
      "    Uninstalling lxml-4.6.4:\n",
      "      Successfully uninstalled lxml-4.6.4\n",
      "Successfully installed awswrangler-2.14.0 jsonpath-ng-1.5.3 lxml-4.9.2 numpy-1.18.5 opensearch-py-1.1.0 pg8000-1.22.1 progressbar2-3.55.0 pymysql-1.0.2 python-utils-3.5.2 redshift-connector-2.0.910 requests-aws4auth-1.2.2 scramp-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Office365-REST-Python-Client\n",
    "!pip install office365\n",
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "31575c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import logging\n",
    "import boto3\n",
    "import os\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import struct\n",
    "\n",
    "from subprocess import call\n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2fff9376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# base_excepciones_banderas_rojas.xlsx\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "## cargamos todas las claves de acceso desde las variables de entorno\n",
    "sharepoint_url = \"https://bancoink.sharepoint.com/sites/data2022/\"\n",
    "client_id = \"a7bc6720-474d-4253-b3ff-6fa0e36de593\"\n",
    "DECRYPTED = \"9Qxc6nz6yZ/AR4z7eu0sXEtlBe84IuoGg5F5BEzxsqc=\"\n",
    "\n",
    "folder_url = \"/sites/data2022/Documentos%20compartidos%2Fencaje_project/\"\n",
    "bucket_name = 'cnk-datalake' \n",
    "file_name = 'Historico_arqueos_data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "63390e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_scheduled=datetime.today()-timedelta(days=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "471aa504",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_num=\"'\"+str(10)+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "297b7ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo xlsx descargado....\n"
     ]
    }
   ],
   "source": [
    "context_auth = AuthenticationContext(sharepoint_url)\n",
    "context_auth.acquire_token_for_app(client_id, DECRYPTED)\n",
    "\n",
    "ctx = ClientContext(sharepoint_url, context_auth)\n",
    "web = ctx.web\n",
    "ctx.load(web)\n",
    "ctx.execute_query()\n",
    "\n",
    "path_file = folder_url + file_name \n",
    "\n",
    "response = File.open_binary(ctx, path_file)\n",
    "#\n",
    "\n",
    "path_file_lambda_xlsx = file_name\n",
    "\n",
    "path_file_lambda_csv = \"archivo.csv\"\n",
    "\n",
    "with open(path_file_lambda_xlsx, \"wb\") as local_file:\n",
    "    local_file.write(response.content)\n",
    "    print(\"Archivo xlsx descargado....\")\n",
    "\n",
    "day_schedule=datetime.today()-timedelta(days=int(days_num.replace(\"'\",\"\")))\n",
    "    \n",
    "## calling the data from sharepoint and leaving just the last 10 days\n",
    "data=pd.read_excel(path_file_lambda_xlsx,engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "14593d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_query=f\"\"\"\n",
    "SELECT so.\"service_order_id\",so.\"service_order_status\",\n",
    "sos.\"service_order_status_name\",so.\"service_order_updated_date\",\n",
    "so.\"service_order_created_date\",so.\"service_order_piggybank_id\",\n",
    "so.\"service_order_type\",sot.\"service_type_name\",so.\"service_order_sequence\",\n",
    "so.\"service_order_canceled_by\",so.\"service_order_canceled_date\",\n",
    "so.\"service_order_door_opened_date\",so.\"service_order_door_closed_date\",\n",
    "sod.\"value\",sod.\"created_at\",pgb.\"piggy_bank_operational_account\",\n",
    "cast(json_extract(sod.\"detail\",'$[0].quantity') as Integer) as \"50_amount\",\n",
    "cast(json_extract(sod.\"detail\",'$[1].quantity') as Integer) as \"100_amount\",\n",
    "cast(json_extract(sod.\"detail\",'$[2].quantity') as Integer) as \"200_amount\",\n",
    "cast(json_extract(sod.\"detail\",'$[3].quantity') as Integer) as \"500_amount\",\n",
    "cast(json_extract(sod.\"detail\",'$[4].quantity') as Integer) as \"1000_amount\",\n",
    "gc.\"maplocation_correct\"\n",
    "FROM \"piggybank\".\"service_orders\" as so LEFT JOIN \n",
    "\"piggybank\".\"service_order_details\" as sod\n",
    "ON so.\"service_order_id\"=sod.\"service_order_id\"\n",
    "LEFT JOIN \"AwsDataCatalog\".\"cnk_datalake\".\"ow_etl_hc_geolocation\" as gc\n",
    "ON so.\"service_order_piggybank_id\"=gc.\"piggy_bank_id\"\n",
    "LEFT JOIN \"piggybank\".\"service_order_status\" sos\n",
    "ON so.\"service_order_status\"=sos.\"service_order_status_id\"\n",
    "LEFT JOIN \"piggybank\".\"service_types\" sot\n",
    "ON so.\"service_order_type\"=sot.\"service_type_id\"\n",
    "LEFT JOIN \"piggybank\".\"piggy_bank\" pgb\n",
    "ON so.\"service_order_piggybank_id\"=pgb.\"piggy_bank_id\"\n",
    "where so.\"service_order_created_date\">cast(current_date - interval {days_num} day as timestamp)\n",
    "AND so.\"service_order_id\" not in (SELECT distinct(\"service_order_id\") FROM \"AwsDataCatalog\".\"cnk_datalake\".\"arqueo_conciliados\");\n",
    "\"\"\"\n",
    "\n",
    "data_aurora=wr.athena.read_sql_query(string_query,\n",
    "                                     database=\"piggybank\",\n",
    "                                     data_source=\"aurora_coink\",\n",
    "                                     ctas_approach=False,\n",
    "                                     s3_output='s3://cnk-datalake/experimentos001/athena_datawrangler/encaje/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "73cb3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just leave the service_orders that corresponds with \"arqueos\"\n",
    "data_aurora=data_aurora[data_aurora[\"service_type_name\"]==\"VAULT_ACCESS\"]\n",
    "\n",
    "## leave only the service_orders that were finished already\n",
    "data_aurora=data_aurora[(data_aurora[\"service_order_status_name\"]==\"FINISHED\") | (data_aurora[\"service_order_status_name\"]==\"DOOR_CLOSED\") | (data_aurora[\"service_order_status_name\"]==\"DOOR_OPENED\") | (data_aurora[\"service_order_status_name\"]==\"FINISHED_FROM_OPERATOR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f902a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform the data to the same type to merge it\n",
    "data_aurora[\"service_order_sequence\"]=data_aurora[\"service_order_sequence\"].astype(int)\n",
    "data[\"service_order_sequence\"]=data[\"service_order_sequence\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3470c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## confirm that there are not service orders without a match in total_details.\n",
    "data_aurora=data_aurora[~(data_aurora['value'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7cee6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring the data from the forms to compare if the data has been sent previously\n",
    "string_query_1=f\"\"\"\n",
    "SELECT * FROM \"AwsDataCatalog\".\"cnk_datalake\".\"arqueo_conciliados\"\n",
    "WHERE cast(\"fecha_de_envio_formulario\" as timestamp)>cast(current_date - interval {days_num} day as timestamp);\n",
    "\"\"\"\n",
    "data_aurora_form=wr.athena.read_sql_query(string_query_1,\n",
    "                                     database=\"cnk_datalake\",\n",
    "                                     data_source=\"AwsDataCatalog\",\n",
    "                                     s3_output='s3://cnk-datalake/experimentos001/athena_datawrangler/encaje_3/')\n",
    "\n",
    "## create a column so we can identify the registers that have already been sent\n",
    "data_aurora_form[\"merged\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5007fdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_order_id</th>\n",
       "      <th>nombre_operario</th>\n",
       "      <th>empresa</th>\n",
       "      <th>email</th>\n",
       "      <th>ciudad</th>\n",
       "      <th>maplocation</th>\n",
       "      <th>fecha</th>\n",
       "      <th>es_reemplazo</th>\n",
       "      <th>solucionado</th>\n",
       "      <th>fecha_de_envio_formulario</th>\n",
       "      <th>...</th>\n",
       "      <th>1000_amount</th>\n",
       "      <th>50_coin_amount</th>\n",
       "      <th>100_coin_amount</th>\n",
       "      <th>200_coin_amount</th>\n",
       "      <th>500_coin_amount</th>\n",
       "      <th>1000_coin_amount</th>\n",
       "      <th>piggy_bank_operational_account</th>\n",
       "      <th>core_amount</th>\n",
       "      <th>value_difference_core_vs_arqueo</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53917d56-7461-4f62-906f-17c77f6ae157</td>\n",
       "      <td>Juan Carlos Oviedo</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>CC Cañaveral - Segundo Piso</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 22:55:46</td>\n",
       "      <td>...</td>\n",
       "      <td>1557</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>0000000256</td>\n",
       "      <td>5314700.0</td>\n",
       "      <td>-5000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1209dc88-884e-457d-bde6-67ae221a33cc</td>\n",
       "      <td>juan alvarez</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>CC Plaza Imperial - Plaza Trombos</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:32:17</td>\n",
       "      <td>...</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0000000164</td>\n",
       "      <td>3930500.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>831fd9e2-c135-4d0c-a897-0492f32e2f44</td>\n",
       "      <td>Juan Alvarez</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>CC Unicentro - Salida Peatonal 8</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:34:25</td>\n",
       "      <td>...</td>\n",
       "      <td>747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0000000183</td>\n",
       "      <td>2239700.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76fa0724-29e5-4cdd-a7a1-95e818ec66ba</td>\n",
       "      <td>Marcelo Mejia</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>CC Plaza de las Américas - Plaza Central</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:22:55</td>\n",
       "      <td>...</td>\n",
       "      <td>3991</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>5117.0</td>\n",
       "      <td>6706.0</td>\n",
       "      <td>6737.0</td>\n",
       "      <td>3986.0</td>\n",
       "      <td>0000000060</td>\n",
       "      <td>9285300.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967b86f3-f5d8-40f6-995c-8c680c815422</td>\n",
       "      <td>juan alvarez</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>Universidad de los Andes - ML Piso 2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:39:28</td>\n",
       "      <td>...</td>\n",
       "      <td>420</td>\n",
       "      <td>617.0</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>0000000013</td>\n",
       "      <td>1661250.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1bfcef53-904d-43dc-bd72-d294699900b2</td>\n",
       "      <td>juan carlos oviedo</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>CC Megamall - Primer Piso</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:18:40</td>\n",
       "      <td>...</td>\n",
       "      <td>1124</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>5182.0</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>0000000229</td>\n",
       "      <td>4653250.0</td>\n",
       "      <td>23350.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cdc36a4f-fc17-4a77-acf6-dfa0b4baee2d</td>\n",
       "      <td>Juan alvarez</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>TM Transmilenio Portal Américas - Ingreso Peat...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:29:59</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0000000205</td>\n",
       "      <td>1208900.0</td>\n",
       "      <td>36350.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a67d671b-a11c-4cb7-822a-4fb654de804a</td>\n",
       "      <td>Juan Carlos Oviedo</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>CC La Florida - Primer Piso</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 22:53:16</td>\n",
       "      <td>...</td>\n",
       "      <td>493</td>\n",
       "      <td>613.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0000000257</td>\n",
       "      <td>2334450.0</td>\n",
       "      <td>-1500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a5fbeb43-80a0-486f-b697-cb61aabe8713</td>\n",
       "      <td>juan alvarez</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>BOGOTÁ</td>\n",
       "      <td>Universidad de los Andes - LL Piso 2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:37:13</td>\n",
       "      <td>...</td>\n",
       "      <td>553</td>\n",
       "      <td>799.0</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>2366.0</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>0000000015</td>\n",
       "      <td>2076600.0</td>\n",
       "      <td>-750.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99a5c932-2080-4da0-a665-ffb626b99387</td>\n",
       "      <td>juan Carlos Oviedo</td>\n",
       "      <td>RAPICAMBIOS</td>\n",
       "      <td>luisenri.valderrama@gmail.com</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>CC Cuarta Etapa</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-14 23:08:57</td>\n",
       "      <td>...</td>\n",
       "      <td>838</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2141.0</td>\n",
       "      <td>2973.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0000000228</td>\n",
       "      <td>2903650.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       service_order_id     nombre_operario      empresa  \\\n",
       "0  53917d56-7461-4f62-906f-17c77f6ae157  Juan Carlos Oviedo  RAPICAMBIOS   \n",
       "1  1209dc88-884e-457d-bde6-67ae221a33cc        juan alvarez  RAPICAMBIOS   \n",
       "2  831fd9e2-c135-4d0c-a897-0492f32e2f44        Juan Alvarez  RAPICAMBIOS   \n",
       "3  76fa0724-29e5-4cdd-a7a1-95e818ec66ba       Marcelo Mejia  RAPICAMBIOS   \n",
       "4  967b86f3-f5d8-40f6-995c-8c680c815422        juan alvarez  RAPICAMBIOS   \n",
       "5  1bfcef53-904d-43dc-bd72-d294699900b2  juan carlos oviedo  RAPICAMBIOS   \n",
       "6  cdc36a4f-fc17-4a77-acf6-dfa0b4baee2d        Juan alvarez  RAPICAMBIOS   \n",
       "7  a67d671b-a11c-4cb7-822a-4fb654de804a  Juan Carlos Oviedo  RAPICAMBIOS   \n",
       "8  a5fbeb43-80a0-486f-b697-cb61aabe8713        juan alvarez  RAPICAMBIOS   \n",
       "9  99a5c932-2080-4da0-a665-ffb626b99387  juan Carlos Oviedo  RAPICAMBIOS   \n",
       "\n",
       "                           email     ciudad  \\\n",
       "0  luisenri.valderrama@gmail.com  SANTANDER   \n",
       "1  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "2  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "3  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "4  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "5  luisenri.valderrama@gmail.com  SANTANDER   \n",
       "6  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "7  luisenri.valderrama@gmail.com  SANTANDER   \n",
       "8  luisenri.valderrama@gmail.com     BOGOTÁ   \n",
       "9  luisenri.valderrama@gmail.com  SANTANDER   \n",
       "\n",
       "                                         maplocation       fecha es_reemplazo  \\\n",
       "0                        CC Cañaveral - Segundo Piso  2023-03-13           no   \n",
       "1                  CC Plaza Imperial - Plaza Trombos  2023-03-14           no   \n",
       "2                   CC Unicentro - Salida Peatonal 8  2023-03-14           no   \n",
       "3           CC Plaza de las Américas - Plaza Central  2023-03-13           no   \n",
       "4               Universidad de los Andes - ML Piso 2  2023-03-14           no   \n",
       "5                          CC Megamall - Primer Piso  2023-03-13           no   \n",
       "6  TM Transmilenio Portal Américas - Ingreso Peat...  2023-03-14           no   \n",
       "7                        CC La Florida - Primer Piso  2023-03-13           no   \n",
       "8               Universidad de los Andes - LL Piso 2  2023-03-14           no   \n",
       "9                                    CC Cuarta Etapa  2023-03-13           no   \n",
       "\n",
       "  solucionado fecha_de_envio_formulario  ... 1000_amount  50_coin_amount  \\\n",
       "0          no       2023-03-14 22:55:46  ...        1557          1662.0   \n",
       "1          no       2023-03-14 23:32:17  ...        1062             1.0   \n",
       "2          no       2023-03-14 23:34:25  ...         747             0.0   \n",
       "3          no       2023-03-14 23:22:55  ...        3991          1563.0   \n",
       "4          no       2023-03-14 23:39:28  ...         420           617.0   \n",
       "5          no       2023-03-14 23:18:40  ...        1124          1390.0   \n",
       "6          no       2023-03-14 23:29:59  ...         195           427.0   \n",
       "7          no       2023-03-14 22:53:16  ...         493           613.0   \n",
       "8          no       2023-03-14 23:37:13  ...         553           799.0   \n",
       "9          no       2023-03-14 23:08:57  ...         838           558.0   \n",
       "\n",
       "  100_coin_amount 200_coin_amount 500_coin_amount 1000_coin_amount  \\\n",
       "0          4342.0          6482.0          3900.0           1556.0   \n",
       "1          2824.0          3700.0          3680.0           1064.0   \n",
       "2          2036.0          2154.0          1721.0            742.0   \n",
       "3          5117.0          6706.0          6737.0           3986.0   \n",
       "4          1834.0          2226.0          1174.0            415.0   \n",
       "5          3800.0          5182.0          4046.0           1121.0   \n",
       "6          1223.0          2247.0           769.0            195.0   \n",
       "7          2746.0          2251.0          2171.0            495.0   \n",
       "8          2102.0          2366.0          1626.0            541.0   \n",
       "9          2141.0          2973.0          2472.0            831.0   \n",
       "\n",
       "   piggy_bank_operational_account  core_amount  \\\n",
       "0                      0000000256    5314700.0   \n",
       "1                      0000000164    3930500.0   \n",
       "2                      0000000183    2239700.0   \n",
       "3                      0000000060    9285300.0   \n",
       "4                      0000000013    1661250.0   \n",
       "5                      0000000229    4653250.0   \n",
       "6                      0000000205    1208900.0   \n",
       "7                      0000000257    2334450.0   \n",
       "8                      0000000015    2076600.0   \n",
       "9                      0000000228    2903650.0   \n",
       "\n",
       "   value_difference_core_vs_arqueo  merged  \n",
       "0                          -5000.0       1  \n",
       "1                           4050.0       1  \n",
       "2                           2800.0       1  \n",
       "3                           -250.0       1  \n",
       "4                           -200.0       1  \n",
       "5                          23350.0       1  \n",
       "6                          36350.0       1  \n",
       "7                          -1500.0       1  \n",
       "8                           -750.0       1  \n",
       "9                             50.0       1  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aurora_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7c7074bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform the datetime to the bogota time\n",
    "data_aurora[\"service_order_created_date\"]=data_aurora[\"service_order_created_date\"]-timedelta(hours=5, minutes=0)\n",
    "\n",
    "## transform the data from the back to date without hours,minutes, etc\n",
    "data_aurora[\"fecha\"]=[i.date() for i in data_aurora[\"service_order_created_date\"]]\n",
    "data[\"fecha\"]=[i.date() for i in data[\"fecha\"]]\n",
    "#data_aurora_form['fecha']=[i.date() for i in data_aurora_form[\"fecha\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3cac520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see which registers are in both tables\n",
    "data=pd.merge(data,data_aurora_form[[\"service_order_sequence\",\"merged\",\"fecha\",\"maplocation\",\"solucionado\"]],\n",
    "              on=[\"fecha\",\"maplocation\",\"service_order_sequence\"],\n",
    "              how=\"left\")\n",
    "data[\"merged\"].fillna(0,inplace=True)\n",
    "\n",
    "## left just the registers that have't been sent previously\n",
    "data=data[(data[\"merged\"]!=1) & ((data[\"solucionado\"]==\"no\") | (data[\"solucionado\"].isna())) | ((data[\"solucionado\"]==\"no\") & (data[\"es_reemplazo\"]==\"si\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "752c1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## format the columns as string\n",
    "data[\"nombre_operario\"]=[str(i) for i in data[\"nombre_operario\"]]\n",
    "data[\"email\"]=[str(i) for i in data[\"email\"]]\n",
    "data[\"comentarios\"]=[str(i) for i in data[\"comentarios\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "46858b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data.empty:\n",
    "    print(\"no forms data without match\")\n",
    "else:\n",
    "    ## load all data to s3\n",
    "    path_file=\"s3://cnk-datalake/piggybank/arqueo_project/formulario/excel_arqueo.parquet\"\n",
    "\n",
    "    ## save the data in s3\n",
    "    wr.s3.to_parquet(\n",
    "                    df=data,\n",
    "                    path=path_file,\n",
    "                    dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c116ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter only the last 10 days\n",
    "data=data[data['fecha']>=day_scheduled.date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6871e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename maplocation columns so we can do the merge with the next table\n",
    "data_aurora.rename(columns={'maplocation_correct':'maplocation'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a8a2d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging the data from the sharepoint with aurora data\n",
    "data_merged=pd.merge(data,data_aurora,on=[\"fecha\",\"maplocation\",\"service_order_sequence\"],how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "73f7f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diference in pesos from the back and the form submitted by the company\n",
    "data_merged[\"value_difference_back_arqueo\"]=data_merged[\"value\"]-data_merged[\"monto total encontrado\"]\n",
    "\n",
    "## rename the columns for the understanding\n",
    "data_merged.rename(columns={\"value\":\"monto_back\",\"monto total encontrado\":\"monto_arqueo\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ddd5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select just the columns that we want to use\n",
    "data_wo_col=data_merged[['nombre_operario', 'empresa',\n",
    "       'ciudad', 'maplocation', 'fecha',\n",
    "       'fecha de envio formulario', 'comentarios','service_order_sequence',\n",
    "       'service_order_updated_date', 'service_order_created_date',\n",
    "       'service_order_door_opened_date', 'service_order_door_closed_date','monto_arqueo',\n",
    "       'monto_back','value_difference_back_arqueo',\"piggy_bank_operational_account\",\"merged\"]]\n",
    "\n",
    "## data to storei in the excel\n",
    "data_merged=data_merged[['service_order_id','nombre_operario', 'empresa', 'email',\n",
    "       'ciudad', 'maplocation', 'fecha','es_reemplazo','solucionado',\n",
    "       'fecha de envio formulario', 'comentarios','service_order_sequence',\n",
    "       'service_order_updated_date', 'service_order_created_date',\n",
    "       'service_order_door_opened_date', 'service_order_door_closed_date','monto_arqueo',\n",
    "       'monto_back','value_difference_back_arqueo',\n",
    "       '50_amount', '100_amount', '200_amount','500_amount', '1000_amount',\n",
    "       '50_coin_amount', '100_coin_amount','200_coin_amount', '500_coin_amount', '1000_coin_amount','piggy_bank_operational_account']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "66b4cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data that already mergedto a route in s3\n",
    "data_merged_inner=data_merged[(~((data_merged[\"empresa\"].isna())|(data_merged[\"service_order_id\"].isna()))) | ((data_merged[\"es_reemplazo\"]==\"si\")&((data_merged[\"solucionado\"]==\"no\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73769637",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to load row by row the data to s3\n",
    "def funct_load_data(data_inner,data_columns):\n",
    "    temp=pd.DataFrame(data=[data_inner],columns=data_columns)\n",
    "    path_file=\"s3://cnk-datalake/piggybank/arqueo_project/conciliados/\"+str(temp[\"fecha\"].tolist()[0]).replace(\" \",\"_\")+\"_\"+str(temp[\"maplocation\"].tolist()[0]).replace(\" \",\"_\")+\"_\"+str(temp[\"service_order_sequence\"].tolist()[0]).replace(\" \",\"_\")\n",
    "    \n",
    "    if temp[\"es_reemplazo\"].tolist()[0]==\"no\":\n",
    "        \n",
    "        temp['solucionado']='no'\n",
    "        ## save each row into s3\n",
    "        wr.s3.to_parquet(\n",
    "                df=temp,\n",
    "                path=path_file,\n",
    "                dataset=False\n",
    "            )\n",
    "    elif (temp[\"es_reemplazo\"].tolist()[0]==\"si\") & (temp[\"solucionado\"].tolist()[0]==\"no\"):\n",
    "        \n",
    "        ## bring the log that corresponds with the observation to replace\n",
    "        temp_1=wr.s3.read_parquet(path_file)\n",
    "        \n",
    "        for i in ['nombre_operario','empresa','email','ciudad','es_reemplazo','50_coin_amount',\n",
    "           '100_coin_amount', '200_coin_amount', '500_coin_amount',\n",
    "           '1000_coin_amount', 'monto_arqueo',\n",
    "           'fecha de envio formulario', 'comentarios', 'solucionado']:\n",
    "            \n",
    "            temp_1[i]=temp[i]\n",
    "        \n",
    "        ## updating the database so it knows that the log corresponds with a replacement\n",
    "        temp_1['solucionado']='si'\n",
    "        \n",
    "        ## agregar aca que recalcule la diferencia entre back y arqueo\n",
    "        temp_1['value_difference_back_arqueo']=temp_1['monto_back']-temp_1['monto_arqueo']\n",
    "        temp_1['value_difference_core_vs_arqueo']=temp_1['core_amount']-temp_1['monto_arqueo']\n",
    "        \n",
    "        ## copy the temp so we can load it into s3\n",
    "        temp=temp_1[temp.columns.tolist()]\n",
    "        \n",
    "        ## save each row into s3\n",
    "        wr.s3.to_parquet(\n",
    "                df=temp,\n",
    "                path=path_file,\n",
    "                dataset=False)\n",
    "        \n",
    "    return list(temp.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1f9bb03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'funct_load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4783ced7c382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# load data to s3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mdatos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunct_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mdata_merged_inner_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-4783ced7c382>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# load data to s3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mdatos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunct_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mdata_merged_inner_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_merged_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'funct_load_data' is not defined"
     ]
    }
   ],
   "source": [
    "if data_merged_inner.empty:\n",
    "    table_1=pd.DataFrame(columns=[\"empresa\",\"ciudad\",\"fecha\",\"maplocation\",'core_amount',\"monto_arqueo\",\"monto_back\",\"value_difference_back_arqueo\",'value_difference_core_vs_arqueo',\"service_order_sequence\",\"piggy_bank_operational_account\"])\n",
    "else:\n",
    "    # import last two service order logs for each piggybank\n",
    "    string_query = '''\n",
    "        SELECT \n",
    "            so.\"service_order_id\",\n",
    "            so.\"service_order_created_date\",\n",
    "            gc.\"maplocation_correct\",\n",
    "            gc.\"piggy_bank_id\"\n",
    "        FROM \"piggybank\".\"service_orders\" as so\n",
    "        LEFT JOIN \"AwsDataCatalog\".\"cnk_datalake\".\"ow_etl_hc_geolocation\" as gc\n",
    "        ON so.\"service_order_piggybank_id\"= gc.\"piggy_bank_id\"\n",
    "        WHERE \"service_order_status\" in (5,6,7,9) and \"service_order_type\"= 2;\n",
    "    '''\n",
    "\n",
    "    sub_data_aurora=wr.athena.read_sql_query(string_query,\n",
    "                                         database=\"piggybank\",\n",
    "                                         data_source=\"aurora_coink\",\n",
    "                                         ctas_approach=False,\n",
    "                                         s3_output='s3://cnk-datalake/experimentos001/athena_datawrangler/encaje/')\n",
    "    \n",
    "    # sort logs values by the creation date of service date \n",
    "    sub_data_aurora = sub_data_aurora.sort_values(by=['service_order_created_date'])\n",
    "    # change timezone from UTC to Bogota\n",
    "    #sub_data_aurora['service_order_created_date'] = [(datetime.strptime(str(x)[0:18], '%Y-%m-%d %H:%M:%S') - timedelta(hours=5, minutes=0)) for x in sub_data_aurora['service_order_created_date']]\n",
    "    sub_data_aurora['service_order_created_date']=sub_data_aurora['service_order_created_date']-timedelta(hours=5,minutes=0)\n",
    "    # create a 1 step lag variable for each maplocation\n",
    "    sub_data_aurora['shift_date'] = sub_data_aurora.groupby(['maplocation_correct']).service_order_created_date.shift(1)\n",
    "    # take the difference between creation date and its lag\n",
    "    sub_data_aurora['time_delta'] = sub_data_aurora['service_order_created_date'] - sub_data_aurora['shift_date']\n",
    "    # subset the log data so that only the most recent log for each maplocation in the report table 1 are seen\n",
    "    table_1_data = data_merged_inner[['service_order_created_date', 'maplocation']]\n",
    "    #table_1_data['service_order_created_date'] =  [datetime.strptime(str(x)[0:18], '%Y-%m-%d %H:%M:%S') for x in table_1_data['service_order_created_date']]\n",
    "    table_1_data = table_1_data.rename(columns={'maplocation':'maplocation_correct'})\n",
    "    temp = pd.merge(sub_data_aurora, table_1_data, on=['service_order_created_date', 'maplocation_correct'], how='inner').drop_duplicates(subset=['service_order_created_date', 'maplocation_correct'])\n",
    "    temp.shift_date = pd.to_datetime(temp.shift_date)\n",
    "    \n",
    "    # check if there are piggybanks which are having their first time of cash counting\n",
    "    first_time = temp[temp.shift_date.isna()].piggy_bank_id.tolist()\n",
    "    if len(first_time) > 0:\n",
    "        # import piggybank creation date in database\n",
    "        oinks_data = wr.s3.read_parquet(path='s3://cnk-datalake/maplocation/Output/etl_hc_geolocation/')\n",
    "        # select variables of interest\n",
    "        oinks_data = oinks_data[['created_date', 'piggy_bank_id']]\n",
    "        # select piggybanks which are having their first time of cash counting\n",
    "        first_time_oinks = oinks_data[oinks_data.piggy_bank_id.isin(first_time)]\n",
    "        # select the minimum date between creation date vector and last time of cash counting vector\n",
    "        start_date = min(temp.shift_date.min(),first_time_oinks.created_date.min())\n",
    "        # select the date as start_date - 1 day\n",
    "        date_str = datetime.strftime(start_date - timedelta(days=1), \"%Y-%m-%d\")\n",
    "    # if there are no piggybanks which are having their first time of cash counting, use the minimum of the last time of cash counting vector\n",
    "    else:  date_str = datetime.strftime(temp.shift_date.min() - timedelta(days=1), \"%Y-%m-%d\")\n",
    "    date_str\n",
    "    \n",
    "    # import transactional data from piggybanks leaving only approved transactions\n",
    "    # since the minimum date overall required piggybanks (date_str)\n",
    "    # for only the requested piggybanks\n",
    "    string_query = \"\"\"SELECT \n",
    "    cr.transfer_id, \n",
    "    cr.amount,\n",
    "    cr.creation_date,\n",
    "    CAST(json_extract(cr.associated_data, '$.location_id') as varchar) as location_id,\n",
    "    CAST(json_extract(cr.associated_data, '$.piggybank_id') as varchar) as piggybank_id\n",
    "    FROM \"core\".\"transfer_view\" as cr\n",
    "    WHERE CAST(json_extract(cr.associated_data, '$.piggybank_id') as varchar) in \"\"\" + \"('\"+ \"', '\".join(temp['piggy_bank_id'].tolist()) + \"')\" + \"AND (CAST(cr.creation_date as date) > CAST('\" + date_str + \"' AS DATE)) AND cr.status_id = 2 ORDER BY CAST(cr.creation_date as date) ASC;\"\n",
    "\n",
    "    Athenadf = wr.athena.read_sql_query(string_query, \n",
    "                                         database=\"core\",\n",
    "                                         data_source=\"aurora_coink\",\n",
    "                                        ctas_approach=False,\n",
    "                                        s3_output = 's3://cnk-datalake/experimentos001/athena_datawrangler/')\n",
    "    # change timezone from UTC to Bogota\n",
    "    Athenadf['creation_date'] = [(datetime.strptime(str(x)[0:18], '%Y-%m-%d %H:%M:%S') - timedelta(hours=5, minutes=0)).strftime(\"%Y-%m-%d %H:%M:%S\") for x in Athenadf['creation_date']]\n",
    "    Athenadf['creation_date'] = pd.to_datetime(Athenadf.creation_date)\n",
    "    # sort values using creation date\n",
    "    Athenadf = Athenadf.sort_values(by=['creation_date'])\n",
    "    \n",
    "    # information store list\n",
    "    empty_list = []\n",
    "    # for each piggybank id\n",
    "    for i,z in zip(temp.piggy_bank_id.tolist(),temp.service_order_created_date.tolist()):\n",
    "        # define start date and end date\n",
    "        start_date = temp[(temp.piggy_bank_id == i) & (temp.service_order_created_date == z)].shift_date.iloc[0]\n",
    "        end_date = temp[(temp.piggy_bank_id == i) & (temp.service_order_created_date == z)].service_order_created_date.iloc[0]\n",
    "        # if there is no start date (first time)\n",
    "        if pd.isnull(start_date): \n",
    "            # sum amount until end date\n",
    "            target_df = Athenadf[(Athenadf.piggybank_id == i) & (Athenadf.creation_date <= end_date)]\n",
    "            empty_list.append([i, target_df.amount.sum(),z])\n",
    "        else:\n",
    "            # sum amount until end date and after start date\n",
    "            target_df = Athenadf[(Athenadf.piggybank_id == i) & (Athenadf.creation_date <= end_date) & (Athenadf.creation_date > start_date)]\n",
    "            empty_list.append([i, target_df.amount.sum(),z])\n",
    "    empty_list\n",
    "    \n",
    "    # convert store list to dataframe\n",
    "    core_amount = pd.DataFrame(empty_list, columns=['piggy_bank_id', 'core_amount','service_order_created_date'])\n",
    "    # add maplocation name\n",
    "    core_amount = pd.merge(core_amount, temp[['piggy_bank_id', 'maplocation_correct','service_order_created_date']], how='left', on=['piggy_bank_id','service_order_created_date'])\n",
    "    # drop piggybank id\n",
    "    core_amount = core_amount.drop(columns=['piggy_bank_id'])\n",
    "    # rename columns\n",
    "    core_amount.columns = ['core_amount','service_order_created_date', 'maplocation']\n",
    "    \n",
    "    # add data to table 1\n",
    "    data_merged_inner = pd.merge(data_merged_inner, core_amount, on =['maplocation','service_order_created_date'], how='left')\n",
    "    data_merged_inner['core_amount'] = pd.to_numeric(data_merged_inner['core_amount'])\n",
    "    data_merged_inner['value_difference_core_vs_arqueo'] = data_merged_inner['core_amount'] - data_merged_inner['monto_arqueo']\n",
    "    \n",
    "    # load data to s3\n",
    "    datos=data_merged_inner.apply(lambda x: funct_load_data(data_inner=list(x),data_columns=data_merged_inner.columns.tolist()),axis=1)\n",
    "    data_merged_inner_1=pd.DataFrame(data=[datos[i] for i in datos.index],columns=data_merged_inner.columns.tolist())\n",
    "    \n",
    "    ## table with the registers that have a difference of more than 10k\n",
    "    table_1=data_merged_inner_1[[\"empresa\",\"ciudad\",\"fecha\",\"maplocation\",'core_amount',\"monto_arqueo\",\"monto_back\",\"value_difference_back_arqueo\",'value_difference_core_vs_arqueo',\"service_order_sequence\",\"piggy_bank_operational_account\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21d08ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## table with registers from the form that had no match in the back\n",
    "table_2=data_wo_col[(data_wo_col[\"piggy_bank_operational_account\"].isna()) & (data_wo_col[\"merged\"]==0)][['nombre_operario', 'empresa', 'ciudad', 'maplocation', 'fecha','monto_arqueo', 'comentarios', 'service_order_sequence']]\n",
    "\n",
    "## table with registers on the back that have no match in forms\n",
    "table_3=data_merged[data_wo_col[\"monto_arqueo\"].isna()][[\"maplocation\",\"service_order_id\",\"service_order_sequence\",\"service_order_created_date\",\"monto_back\",\"piggy_bank_operational_account\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a5c4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## consolidate the database and save it in the temporal\n",
    "final_report=pd.concat([table_1,table_2,table_3],axis=0)\n",
    "final_report.to_excel('/tmp/reporte.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6914998",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding the number of days since the service_order.\n",
    "table_3['Dias']=[i.days for i in datetime.today()-table_3['service_order_created_date']]\n",
    "table_3.sort_values('Dias',inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f7847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
